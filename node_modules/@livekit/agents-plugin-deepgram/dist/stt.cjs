"use strict";
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);
var stt_exports = {};
__export(stt_exports, {
  STT: () => STT,
  SpeechStream: () => SpeechStream
});
module.exports = __toCommonJS(stt_exports);
var import_agents = require("@livekit/agents");
var import_ws = require("ws");
const API_BASE_URL_V1 = "wss://api.deepgram.com/v1/listen";
const defaultSTTOptions = {
  apiKey: process.env.DEEPGRAM_API_KEY,
  language: "en-US",
  detectLanguage: false,
  interimResults: true,
  punctuate: true,
  model: "nova-2-general",
  smartFormat: true,
  noDelay: true,
  endpointing: 25,
  fillerWords: false,
  sampleRate: 16e3,
  numChannels: 1,
  keywords: [],
  keyterm: [],
  profanityFilter: false,
  dictation: false,
  diarize: false,
  numerals: false
};
class STT extends import_agents.stt.STT {
  #opts;
  #logger = (0, import_agents.log)();
  label = "deepgram.STT";
  constructor(opts = defaultSTTOptions) {
    super({
      streaming: true,
      interimResults: opts.interimResults ?? defaultSTTOptions.interimResults
    });
    if (opts.apiKey === void 0 && defaultSTTOptions.apiKey === void 0) {
      throw new Error(
        "Deepgram API key is required, whether as an argument or as $DEEPGRAM_API_KEY"
      );
    }
    this.#opts = { ...defaultSTTOptions, ...opts };
    if (this.#opts.detectLanguage) {
      this.#opts.language = void 0;
    } else if (this.#opts.language && !["en-US", "en"].includes(this.#opts.language) && [
      "nova-2-meeting",
      "nova-2-phonecall",
      "nova-2-finance",
      "nova-2-conversationalai",
      "nova-2-voicemail",
      "nova-2-video",
      "nova-2-medical",
      "nova-2-drivethru",
      "nova-2-automotive",
      "nova-3-general"
    ].includes(this.#opts.model)) {
      this.#logger.warn(
        `${this.#opts.model} does not support language ${this.#opts.language}, falling back to nova-2-general`
      );
      this.#opts.model = "nova-2-general";
    }
  }
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  async _recognize(_) {
    throw new Error("Recognize is not supported on Deepgram STT");
  }
  updateOptions(opts) {
    this.#opts = { ...this.#opts, ...opts };
  }
  stream() {
    return new SpeechStream(this, this.#opts);
  }
}
class SpeechStream extends import_agents.stt.SpeechStream {
  #opts;
  #audioEnergyFilter;
  #logger = (0, import_agents.log)();
  #speaking = false;
  #resetWS = new import_agents.Future();
  label = "deepgram.SpeechStream";
  constructor(stt2, opts) {
    super(stt2);
    this.#opts = opts;
    this.closed = false;
    this.#audioEnergyFilter = new import_agents.AudioEnergyFilter();
    this.#run();
  }
  async #run(maxRetry = 32) {
    let retries = 0;
    let ws;
    while (!this.input.closed) {
      const streamURL = new URL(API_BASE_URL_V1);
      const params = {
        model: this.#opts.model,
        punctuate: this.#opts.punctuate,
        smart_format: this.#opts.smartFormat,
        dictation: this.#opts.dictation,
        diarize: this.#opts.diarize,
        numerals: this.#opts.numerals,
        no_delay: this.#opts.noDelay,
        interim_results: this.#opts.interimResults,
        encoding: "linear16",
        vad_events: true,
        sample_rate: this.#opts.sampleRate,
        channels: this.#opts.numChannels,
        endpointing: this.#opts.endpointing || false,
        filler_words: this.#opts.fillerWords,
        keywords: this.#opts.keywords.map((x) => x.join(":")),
        keyterm: this.#opts.keyterm,
        profanity_filter: this.#opts.profanityFilter,
        language: this.#opts.language
      };
      Object.entries(params).forEach(([k, v]) => {
        if (v !== void 0) {
          if (typeof v === "string" || typeof v === "number" || typeof v === "boolean") {
            streamURL.searchParams.append(k, encodeURIComponent(v));
          } else {
            v.forEach((x) => streamURL.searchParams.append(k, encodeURIComponent(x)));
          }
        }
      });
      ws = new import_ws.WebSocket(streamURL, {
        headers: { Authorization: `Token ${this.#opts.apiKey}` }
      });
      try {
        await new Promise((resolve, reject) => {
          ws.on("open", resolve);
          ws.on("error", (error) => reject(error));
          ws.on("close", (code) => reject(`WebSocket returned ${code}`));
        });
        await this.#runWS(ws);
      } catch (e) {
        if (retries >= maxRetry) {
          throw new Error(`failed to connect to Deepgram after ${retries} attempts: ${e}`);
        }
        const delay = Math.min(retries * 5, 10);
        retries++;
        this.#logger.warn(
          `failed to connect to Deepgram, retrying in ${delay} seconds: ${e} (${retries}/${maxRetry})`
        );
        await new Promise((resolve) => setTimeout(resolve, delay * 1e3));
      }
    }
    this.closed = true;
  }
  updateOptions(opts) {
    this.#opts = { ...this.#opts, ...opts };
    this.#resetWS.resolve();
  }
  async #runWS(ws) {
    this.#resetWS = new import_agents.Future();
    let closing = false;
    const keepalive = setInterval(() => {
      try {
        ws.send(JSON.stringify({ type: "KeepAlive" }));
      } catch {
        clearInterval(keepalive);
        return;
      }
    }, 5e3);
    const sendTask = async () => {
      const samples100Ms = Math.floor(this.#opts.sampleRate / 10);
      const stream = new import_agents.AudioByteStream(
        this.#opts.sampleRate,
        this.#opts.numChannels,
        samples100Ms
      );
      for await (const data of this.input) {
        let frames;
        if (data === SpeechStream.FLUSH_SENTINEL) {
          frames = stream.flush();
        } else if (data.sampleRate === this.#opts.sampleRate || data.channels === this.#opts.numChannels) {
          frames = stream.write(data.data.buffer);
        } else {
          throw new Error(`sample rate or channel count of frame does not match`);
        }
        for await (const frame of frames) {
          if (this.#audioEnergyFilter.pushFrame(frame)) {
            ws.send(frame.data.buffer);
          }
        }
      }
      closing = true;
      ws.send(JSON.stringify({ type: "CloseStream" }));
    };
    const wsMonitor = new Promise(
      (_, reject) => ws.once("close", (code, reason) => {
        if (!closing) {
          this.#logger.error(`WebSocket closed with code ${code}: ${reason}`);
          reject();
        }
      })
    );
    const listenTask = async () => {
      while (!this.closed && !closing) {
        try {
          await new Promise((resolve) => {
            ws.once("message", (data) => resolve(data));
          }).then((msg) => {
            const json = JSON.parse(msg.toString());
            switch (json["type"]) {
              case "SpeechStarted": {
                if (this.#speaking) return;
                this.#speaking = true;
                this.queue.put({ type: import_agents.stt.SpeechEventType.START_OF_SPEECH });
                break;
              }
              // see this page:
              // https://developers.deepgram.com/docs/understand-endpointing-interim-results#using-endpointing-speech_final
              // for more information about the different types of events
              case "Results": {
                const isFinal = json["is_final"];
                const isEndpoint = json["speech_final"];
                const alternatives = liveTranscriptionToSpeechData(this.#opts.language, json);
                if (alternatives[0] && alternatives[0].text) {
                  if (!this.#speaking) {
                    this.#speaking = true;
                    this.queue.put({ type: import_agents.stt.SpeechEventType.START_OF_SPEECH });
                  }
                  if (isFinal) {
                    this.queue.put({
                      type: import_agents.stt.SpeechEventType.FINAL_TRANSCRIPT,
                      alternatives: [alternatives[0], ...alternatives.slice(1)]
                    });
                  } else {
                    this.queue.put({
                      type: import_agents.stt.SpeechEventType.INTERIM_TRANSCRIPT,
                      alternatives: [alternatives[0], ...alternatives.slice(1)]
                    });
                  }
                }
                if (isEndpoint && this.#speaking) {
                  this.#speaking = false;
                  this.queue.put({ type: import_agents.stt.SpeechEventType.END_OF_SPEECH });
                }
                break;
              }
              case "Metadata": {
                break;
              }
              default: {
                this.#logger.child({ msg: json }).warn("received unexpected message from Deepgram");
                break;
              }
            }
          });
        } catch (error) {
          this.#logger.child({ error }).warn("unrecoverable error, exiting");
          break;
        }
      }
    };
    await Promise.race([this.#resetWS.await, Promise.all([sendTask(), listenTask(), wsMonitor])]);
    closing = true;
    ws.close();
    clearInterval(keepalive);
  }
}
const liveTranscriptionToSpeechData = (language, data) => {
  const alts = data["channel"]["alternatives"];
  return alts.map((alt) => ({
    language,
    startTime: alt["words"].length ? alt["words"][0]["start"] : 0,
    endTime: alt["words"].length ? alt["words"][alt["words"].length - 1]["end"] : 0,
    confidence: alt["confidence"],
    text: alt["transcript"]
  }));
};
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
  STT,
  SpeechStream
});
//# sourceMappingURL=stt.cjs.map